{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to NLP\n",
    "\n",
    "We will use spacy library to do pos tagging, stemming and tokenization.\n",
    "\n",
    "Exercise 1: Import spacy and load the module by using [nlp =spacy.load('en_core_web_sm')]\n",
    "\n",
    "Exercise 2: Extract the data from the file War and peace and select a small range of data\n",
    "(Say 10 lists)\n",
    "\n",
    "Exercise 3: Pass this data for tokenizing, stemming and POS tagging\n",
    "\n",
    "Exercise 4: Pass this data to get a more detailed POS tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using NLTK Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('War_And_Peace.txt', 'r') as myfile:\n",
    "    doc = myfile.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of the doc variable is : <class 'str'>  and length is :  3227580\n"
     ]
    }
   ],
   "source": [
    "print(\"Type of the doc variable is :\",type(doc),\" and length is : \",len(doc))\n",
    "doc=doc.replace('\\n',\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc=doc[10000:15000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of the doc variable is : <class 'str'>  and length is :  5000\n"
     ]
    }
   ],
   "source": [
    "print(\"Type of the doc variable is :\",type(doc),\" and length is : \",len(doc))\n",
    "doc=doc.replace('\\n',\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sentence Tokenizer\n",
    "sent=sent_tokenize(doc)\n",
    "len(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print Random sentence using Sent tokenizer \n",
      "\n",
      "Perhaps I don’t understand things, but Austria never has wished, and does not wish, for war.\n",
      "Our gracious sovereign recognizes his high vocation and will be true to it.\n",
      "He will fulfill his vocation and crush the hydra of revolution, which has become more terrible than ever in the person of this murderer and villain!\n",
      "England with her commercial spirit will not and cannot understand the Emperor Alexander’s loftiness of soul.\n",
      "What answer did Novosíltsev get?\n",
      "And what have they promised?\n",
      "Prussia has always declared that Buonaparte is invincible, and that all Europe is powerless before him.... And I don’t believe a word that Hardenburg says, or Haugwitz either.\n",
      "He will save Europe!”  She suddenly paused, smiling at her own impetuosity.\n",
      "Will you give me a cup of tea?”  “In a moment.\n",
      "And also the Abbé Morio.\n",
      "Had you heard?”  “I shall be delighted to meet them,” said the prince.\n",
      "Anna Pávlovna almost closed her eyes to indicate that neither she nor anyone else had a right to criticize what the Empress desired or was pleased with.\n",
      "She added that Her Majesty had deigned to show Baron Funke beaucoup d’estime, and again her face clouded over with sadness.\n",
      "Do you know that since your daughter came out everyone has been enraptured by her?\n"
     ]
    }
   ],
   "source": [
    "print(\"Print Random sentence using Sent tokenizer \\n\")\n",
    "\n",
    "for i in range(10,len(sent),3):\n",
    "    print(sent[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word Tokenizer\n",
    "words=[]\n",
    "for i in range(len(sent)):\n",
    "    words.append(word_tokenize(sent[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print Random words using word tokenizer\n",
      "['Perhaps', 'I', 'don', '’', 't', 'understand', 'things', ',', 'but', 'Austria', 'never', 'has', 'wished', ',', 'and', 'does', 'not', 'wish', ',', 'for', 'war', '.']\n"
     ]
    }
   ],
   "source": [
    "print(\"Print Random words using word tokenizer\")\n",
    "for i in range(10,len(words),1897):\n",
    "        print(words[i])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "new_words=list(chain.from_iterable(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print Random Stemmed Words using word tokenizer\n",
      "sh\n",
      "to\n",
      "be\n",
      "believ\n",
      ".\n",
      "“\n",
      "don\n",
      "’\n",
      "t\n",
      "teas\n",
      "!\n",
      "well\n",
      ",\n",
      "and\n",
      "what\n",
      "ha\n",
      "been\n",
      "decid\n",
      "about\n",
      "novosíltsev\n",
      "’\n",
      "s\n",
      "dispatch\n",
      "?\n",
      "you\n",
      "know\n",
      "everything.\n",
      "”\n",
      "“\n",
      "what\n",
      "can\n",
      "one\n",
      "say\n",
      "about\n",
      "it\n",
      "?\n",
      "”\n",
      "repli\n",
      "the\n",
      "princ\n",
      "in\n",
      "a\n",
      "cold\n",
      ",\n",
      "listless\n",
      "tone\n",
      ".\n",
      "“\n",
      "what\n",
      "ha\n",
      "been\n",
      "decid\n",
      "?\n",
      "they\n",
      "have\n",
      "decid\n",
      "that\n",
      "buonapart\n",
      "ha\n",
      "burnt\n",
      "hi\n",
      "boat\n",
      ",\n",
      "and\n",
      "I\n",
      "believ\n",
      "that\n",
      "we\n",
      "are\n",
      "readi\n",
      "to\n",
      "burn\n",
      "ours.\n",
      "”\n",
      "princ\n",
      "vasíli\n",
      "alway\n",
      "spoke\n",
      "languidli\n",
      ",\n",
      "like\n",
      "an\n",
      "actor\n",
      "repeat\n",
      "a\n",
      "stale\n",
      "part\n",
      ".\n",
      "anna\n",
      "pávlovna\n",
      "schérer\n",
      "on\n",
      "the\n",
      "contrari\n",
      ",\n",
      "despit\n",
      "her\n",
      "forti\n",
      "year\n",
      ",\n",
      "overflow\n",
      "with\n",
      "anim\n",
      "and\n",
      "impuls\n",
      ".\n",
      "To\n",
      "be\n",
      "an\n",
      "enthusiast\n",
      "had\n",
      "becom\n",
      "her\n",
      "social\n",
      "vocat\n",
      "and\n",
      ",\n",
      "sometim\n",
      "even\n",
      "when\n",
      "she\n",
      "did\n",
      "not\n",
      "feel\n",
      "like\n",
      "it\n",
      ",\n",
      "she\n",
      "becam\n",
      "enthusiast\n",
      "in\n",
      "order\n",
      "not\n",
      "to\n",
      "disappoint\n",
      "the\n",
      "expect\n",
      "of\n",
      "those\n",
      "who\n",
      "knew\n",
      "her\n",
      ".\n",
      "the\n",
      "subdu\n",
      "smile\n",
      "which\n",
      ",\n",
      "though\n",
      "it\n",
      "did\n",
      "not\n",
      "suit\n",
      "her\n",
      "fade\n",
      "featur\n",
      ",\n",
      "alway\n",
      "play\n",
      "round\n",
      "her\n",
      "lip\n",
      "express\n",
      ",\n",
      "as\n",
      "in\n",
      "a\n",
      "spoil\n",
      "child\n",
      ",\n",
      "a\n",
      "continu\n",
      "conscious\n",
      "of\n",
      "her\n",
      "charm\n",
      "defect\n",
      ",\n",
      "which\n",
      "she\n",
      "neither\n",
      "wish\n",
      ",\n",
      "nor\n",
      "could\n",
      ",\n",
      "nor\n",
      "consid\n",
      "it\n",
      "necessari\n",
      ",\n",
      "to\n",
      "correct\n",
      ".\n",
      "In\n",
      "the\n",
      "midst\n",
      "of\n",
      "a\n",
      "convers\n",
      "on\n",
      "polit\n",
      "matter\n",
      "anna\n",
      "pávlovna\n",
      "burst\n",
      "out\n",
      ":\n",
      "“\n",
      "Oh\n",
      ",\n",
      "don\n",
      "’\n",
      "t\n",
      "speak\n",
      "to\n",
      "me\n",
      "of\n",
      "austria\n",
      ".\n",
      "perhap\n",
      "I\n",
      "don\n",
      "’\n",
      "t\n",
      "understand\n",
      "thing\n",
      ",\n",
      "but\n",
      "austria\n",
      "never\n",
      "ha\n",
      "wish\n",
      ",\n",
      "and\n",
      "doe\n",
      "not\n",
      "wish\n",
      ",\n",
      "for\n",
      "war\n",
      ".\n",
      "she\n",
      "is\n",
      "betray\n",
      "us\n",
      "!\n",
      "russia\n",
      "alon\n",
      "must\n",
      "save\n",
      "europ\n",
      ".\n",
      "our\n",
      "graciou\n",
      "sovereign\n",
      "recogn\n",
      "hi\n",
      "high\n",
      "vocat\n",
      "and\n",
      "will\n",
      "be\n",
      "true\n",
      "to\n",
      "it\n",
      ".\n",
      "that\n",
      "is\n",
      "the\n",
      "one\n",
      "thing\n",
      "I\n",
      "have\n",
      "faith\n",
      "in\n",
      "!\n",
      "our\n",
      "good\n",
      "and\n",
      "wonder\n",
      "sovereign\n",
      "ha\n",
      "to\n",
      "perform\n",
      "the\n",
      "noblest\n",
      "role\n",
      "on\n",
      "earth\n",
      ",\n",
      "and\n",
      "he\n",
      "is\n",
      "so\n",
      "virtuou\n",
      "and\n",
      "nobl\n",
      "that\n",
      "god\n",
      "will\n",
      "not\n",
      "forsak\n",
      "him\n",
      ".\n",
      "He\n",
      "will\n",
      "fulfil\n",
      "hi\n",
      "vocat\n",
      "and\n",
      "crush\n",
      "the\n",
      "hydra\n",
      "of\n",
      "revolut\n",
      ",\n",
      "which\n",
      "ha\n",
      "becom\n",
      "more\n",
      "terribl\n",
      "than\n",
      "ever\n",
      "in\n",
      "the\n",
      "person\n",
      "of\n",
      "thi\n",
      "murder\n",
      "and\n",
      "villain\n",
      "!\n",
      "We\n",
      "alon\n",
      "must\n",
      "aveng\n",
      "the\n",
      "blood\n",
      "of\n",
      "the\n",
      "just\n",
      "one\n",
      "...\n",
      ".\n",
      "whom\n",
      ",\n",
      "I\n",
      "ask\n",
      "you\n",
      ",\n",
      "can\n",
      "we\n",
      "reli\n",
      "on\n",
      "?\n",
      "...\n",
      "england\n",
      "with\n",
      "her\n",
      "commerci\n",
      "spirit\n",
      "will\n",
      "not\n",
      "and\n",
      "can\n",
      "not\n",
      "understand\n",
      "the\n",
      "emperor\n",
      "alexand\n",
      "’\n",
      "s\n",
      "lofti\n",
      "of\n",
      "soul\n",
      ".\n",
      "she\n",
      "ha\n",
      "refus\n",
      "to\n",
      "evacu\n",
      "malta\n",
      ".\n",
      "she\n",
      "want\n",
      "to\n",
      "find\n",
      ",\n",
      "and\n",
      "still\n",
      "seek\n",
      ",\n",
      "some\n",
      "secret\n",
      "motiv\n",
      "in\n",
      "our\n",
      "action\n",
      ".\n",
      "what\n",
      "answer\n",
      "did\n",
      "novosíltsev\n",
      "get\n",
      "?\n",
      "none\n",
      ".\n",
      "the\n",
      "english\n",
      "have\n",
      "not\n",
      "understood\n",
      "and\n",
      "can\n",
      "not\n",
      "understand\n",
      "the\n",
      "self-abneg\n",
      "of\n",
      "our\n",
      "emperor\n",
      "who\n",
      "want\n",
      "noth\n",
      "for\n",
      "himself\n",
      ",\n",
      "but\n",
      "onli\n",
      "desir\n",
      "the\n",
      "good\n",
      "of\n",
      "mankind\n",
      ".\n",
      "and\n",
      "what\n",
      "have\n",
      "they\n",
      "promis\n",
      "?\n",
      "noth\n",
      "!\n",
      "and\n",
      "what\n",
      "littl\n",
      "they\n",
      "have\n",
      "promis\n",
      "they\n",
      "will\n",
      "not\n",
      "perform\n",
      "!\n",
      "prussia\n",
      "ha\n",
      "alway\n",
      "declar\n",
      "that\n",
      "buonapart\n",
      "is\n",
      "invinc\n",
      ",\n",
      "and\n",
      "that\n",
      "all\n",
      "europ\n",
      "is\n",
      "powerless\n",
      "befor\n",
      "him\n",
      "...\n",
      ".\n",
      "and\n",
      "I\n",
      "don\n",
      "’\n",
      "t\n",
      "believ\n",
      "a\n",
      "word\n",
      "that\n",
      "hardenburg\n",
      "say\n",
      ",\n",
      "or\n",
      "haugwitz\n",
      "either\n",
      ".\n",
      "thi\n",
      "famou\n",
      "prussian\n",
      "neutral\n",
      "is\n",
      "just\n",
      "a\n",
      "trap\n",
      ".\n",
      "I\n",
      "have\n",
      "faith\n",
      "onli\n",
      "in\n",
      "god\n",
      "and\n",
      "the\n",
      "lofti\n",
      "destini\n",
      "of\n",
      "our\n",
      "ador\n",
      "monarch\n",
      ".\n",
      "He\n",
      "will\n",
      "save\n",
      "europ\n",
      "!\n",
      "”\n",
      "she\n",
      "suddenli\n",
      "paus\n",
      ",\n",
      "smile\n",
      "at\n",
      "her\n",
      "own\n",
      "impetuos\n",
      ".\n",
      "“\n",
      "I\n",
      "think\n",
      ",\n",
      "”\n",
      "said\n",
      "the\n",
      "princ\n",
      "with\n",
      "a\n",
      "smile\n",
      ",\n",
      "“\n",
      "that\n",
      "if\n",
      "you\n",
      "had\n",
      "been\n",
      "sent\n",
      "instead\n",
      "of\n",
      "our\n",
      "dear\n",
      "wintzingerod\n",
      "you\n",
      "would\n",
      "have\n",
      "captur\n",
      "the\n",
      "king\n",
      "of\n",
      "prussia\n",
      "’\n",
      "s\n",
      "consent\n",
      "by\n",
      "assault\n",
      ".\n",
      "you\n",
      "are\n",
      "so\n",
      "eloqu\n",
      ".\n",
      "will\n",
      "you\n",
      "give\n",
      "me\n",
      "a\n",
      "cup\n",
      "of\n",
      "tea\n",
      "?\n",
      "”\n",
      "“\n",
      "In\n",
      "a\n",
      "moment\n",
      ".\n",
      "À\n",
      "propo\n",
      ",\n",
      "”\n",
      "she\n",
      "ad\n",
      ",\n",
      "becom\n",
      "calm\n",
      "again\n",
      ",\n",
      "“\n",
      "I\n",
      "am\n",
      "expect\n",
      "two\n",
      "veri\n",
      "interest\n",
      "men\n",
      "tonight\n",
      ",\n",
      "le\n",
      "vicomt\n",
      "de\n",
      "mortemart\n",
      ",\n",
      "who\n",
      "is\n",
      "connect\n",
      "with\n",
      "the\n",
      "montmor\n",
      "through\n",
      "the\n",
      "rohan\n",
      ",\n",
      "one\n",
      "of\n",
      "the\n",
      "best\n",
      "french\n",
      "famili\n",
      ".\n",
      "He\n",
      "is\n",
      "one\n",
      "of\n",
      "the\n",
      "genuin\n",
      "émigré\n",
      ",\n",
      "the\n",
      "good\n",
      "one\n",
      ".\n",
      "and\n",
      "also\n",
      "the\n",
      "abbé\n",
      "morio\n",
      ".\n",
      "Do\n",
      "you\n",
      "know\n",
      "that\n",
      "profound\n",
      "thinker\n",
      "?\n",
      "He\n",
      "ha\n",
      "been\n",
      "receiv\n",
      "by\n",
      "the\n",
      "emperor\n",
      ".\n",
      "had\n",
      "you\n",
      "heard\n",
      "?\n",
      "”\n",
      "“\n",
      "I\n",
      "shall\n",
      "be\n",
      "delight\n",
      "to\n",
      "meet\n",
      "them\n",
      ",\n",
      "”\n",
      "said\n",
      "the\n",
      "princ\n",
      ".\n",
      "“\n",
      "but\n",
      "tell\n",
      "me\n",
      ",\n",
      "”\n",
      "he\n",
      "ad\n",
      "with\n",
      "studi\n",
      "careless\n",
      "as\n",
      "if\n",
      "it\n",
      "had\n",
      "onli\n",
      "just\n",
      "occur\n",
      "to\n",
      "him\n",
      ",\n",
      "though\n",
      "the\n",
      "question\n",
      "he\n",
      "wa\n",
      "about\n",
      "to\n",
      "ask\n",
      "wa\n",
      "the\n",
      "chief\n",
      "motiv\n",
      "of\n",
      "hi\n",
      "visit\n",
      ",\n",
      "“\n",
      "is\n",
      "it\n",
      "true\n",
      "that\n",
      "the\n",
      "dowag\n",
      "empress\n",
      "want\n",
      "baron\n",
      "funk\n",
      "to\n",
      "be\n",
      "appoint\n",
      "first\n",
      "secretari\n",
      "at\n",
      "vienna\n",
      "?\n",
      "the\n",
      "baron\n",
      "by\n",
      "all\n",
      "account\n",
      "is\n",
      "a\n",
      "poor\n",
      "creature.\n",
      "”\n",
      "princ\n",
      "vasíli\n",
      "wish\n",
      "to\n",
      "obtain\n",
      "thi\n",
      "post\n",
      "for\n",
      "hi\n",
      "son\n",
      ",\n",
      "but\n",
      "other\n",
      "were\n",
      "tri\n",
      "through\n",
      "the\n",
      "dowag\n",
      "empress\n",
      "márya\n",
      "fëdorovna\n",
      "to\n",
      "secur\n",
      "it\n",
      "for\n",
      "the\n",
      "baron\n",
      ".\n",
      "anna\n",
      "pávlovna\n",
      "almost\n",
      "close\n",
      "her\n",
      "eye\n",
      "to\n",
      "indic\n",
      "that\n",
      "neither\n",
      "she\n",
      "nor\n",
      "anyon\n",
      "els\n",
      "had\n",
      "a\n",
      "right\n",
      "to\n",
      "critic\n",
      "what\n",
      "the\n",
      "empress\n",
      "desir\n",
      "or\n",
      "wa\n",
      "pleas\n",
      "with\n",
      ".\n",
      "“\n",
      "baron\n",
      "funk\n",
      "ha\n",
      "been\n",
      "recommend\n",
      "to\n",
      "the\n",
      "dowag\n",
      "empress\n",
      "by\n",
      "her\n",
      "sister\n",
      ",\n",
      "”\n",
      "wa\n",
      "all\n",
      "she\n",
      "said\n",
      ",\n",
      "in\n",
      "a\n",
      "dri\n",
      "and\n",
      "mourn\n",
      "tone\n",
      ".\n",
      "As\n",
      "she\n",
      "name\n",
      "the\n",
      "empress\n",
      ",\n",
      "anna\n",
      "pávlovna\n",
      "’\n",
      "s\n",
      "face\n",
      "suddenli\n",
      "assum\n",
      "an\n",
      "express\n",
      "of\n",
      "profound\n",
      "and\n",
      "sincer\n",
      "devot\n",
      "and\n",
      "respect\n",
      "mingl\n",
      "with\n",
      "sad\n",
      ",\n",
      "and\n",
      "thi\n",
      "occur\n",
      "everi\n",
      "time\n",
      "she\n",
      "mention\n",
      "her\n",
      "illustri\n",
      "patro\n",
      ".\n",
      "she\n",
      "ad\n",
      "that\n",
      "her\n",
      "majesti\n",
      "had\n",
      "deign\n",
      "to\n",
      "show\n",
      "baron\n",
      "funk\n",
      "beaucoup\n",
      "d\n",
      "’\n",
      "estim\n",
      ",\n",
      "and\n",
      "again\n",
      "her\n",
      "face\n",
      "cloud\n",
      "over\n",
      "with\n",
      "sad\n",
      ".\n",
      "the\n",
      "princ\n",
      "wa\n",
      "silent\n",
      "and\n",
      "look\n",
      "indiffer\n",
      ".\n",
      "but\n",
      ",\n",
      "with\n",
      "the\n",
      "womanli\n",
      "and\n",
      "courtierlik\n",
      "quick\n",
      "and\n",
      "tact\n",
      "habitu\n",
      "to\n",
      "her\n",
      ",\n",
      "anna\n",
      "pávlovna\n",
      "wish\n",
      "both\n",
      "to\n",
      "rebuk\n",
      "him\n",
      "(\n",
      "for\n",
      "dare\n",
      "to\n",
      "speak\n",
      "as\n",
      "he\n",
      "had\n",
      "done\n",
      "of\n",
      "a\n",
      "man\n",
      "recommend\n",
      "to\n",
      "the\n",
      "empress\n",
      ")\n",
      "and\n",
      "at\n",
      "the\n",
      "same\n",
      "time\n",
      "to\n",
      "consol\n",
      "him\n",
      ",\n",
      "so\n",
      "she\n",
      "said\n",
      ":\n",
      "“\n",
      "now\n",
      "about\n",
      "your\n",
      "famili\n",
      ".\n",
      "Do\n",
      "you\n",
      "know\n",
      "that\n",
      "sinc\n",
      "your\n",
      "daughter\n",
      "came\n",
      "out\n",
      "everyon\n",
      "ha\n",
      "been\n",
      "enraptur\n",
      "by\n",
      "her\n",
      "?\n",
      "they\n",
      "say\n",
      "she\n",
      "is\n",
      "amazingli\n",
      "beautiful.\n",
      "”\n",
      "the\n",
      "princ\n",
      "bow\n",
      "to\n",
      "signifi\n",
      "hi\n",
      "respect\n",
      "and\n",
      "gratitud\n",
      ".\n",
      "“\n",
      "I\n",
      "often\n",
      "think\n",
      ",\n",
      "”\n",
      "she\n",
      "continu\n",
      "after\n",
      "a\n",
      "short\n",
      "paus\n",
      ",\n",
      "draw\n",
      "nearer\n",
      "to\n",
      "the\n",
      "princ\n",
      "and\n",
      "smile\n",
      "amiabl\n",
      "at\n",
      "him\n",
      "as\n",
      "if\n",
      "to\n",
      "show\n",
      "that\n",
      "polit\n",
      "and\n",
      "social\n",
      "topic\n",
      "were\n",
      "end\n",
      "and\n",
      "the\n",
      "time\n",
      "had\n",
      "come\n",
      "fo\n"
     ]
    }
   ],
   "source": [
    "stemmed_words=[]\n",
    "ps=PorterStemmer()\n",
    "print(\"Print Random Stemmed Words using word tokenizer\")\n",
    "for i in range(len(new_words)):\n",
    "    stemmed_words.append(ps.stem(str(new_words[i])))\n",
    "    print(ps.stem(str(new_words[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1032"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stemmed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\n",
      "we\n",
      "like\n",
      "wish\n",
      ",\n",
      "virtuou\n",
      "we\n",
      "english\n",
      "all\n",
      ",\n",
      "tea\n",
      "émigré\n",
      "as\n",
      "wish\n",
      "ha\n",
      "her\n",
      "him\n",
      "amazingli\n"
     ]
    }
   ],
   "source": [
    "for i in range(10,len(stemmed_words),57):\n",
    "        print(stemmed_words[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS Tagging using NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('sh', 'NN'), ('to', 'TO'), ('be', 'VB'), ('believed', 'VBN'), ('.', '.')]\n",
      "[('“', 'JJ'), ('Don', 'NNP'), ('’', 'NNP'), ('t', 'JJ'), ('tease', 'NN'), ('!', '.')]\n",
      "[('Well', 'RB'), (',', ','), ('and', 'CC'), ('what', 'WDT'), ('has', 'VBZ'), ('been', 'VBN'), ('decided', 'VBN'), ('about', 'IN'), ('Novosíltsev', 'NNP'), ('’', 'NNP'), ('s', 'VBD'), ('dispatch', 'NN'), ('?', '.')]\n",
      "[('You', 'PRP'), ('know', 'VBP'), ('everything.', 'JJ'), ('”', 'NNP'), ('“', 'NNP'), ('What', 'WP'), ('can', 'MD'), ('one', 'CD'), ('say', 'VB'), ('about', 'IN'), ('it', 'PRP'), ('?', '.'), ('”', \"''\"), ('replied', 'VBD'), ('the', 'DT'), ('prince', 'NN'), ('in', 'IN'), ('a', 'DT'), ('cold', 'JJ'), (',', ','), ('listless', 'JJ'), ('tone', 'NN'), ('.', '.')]\n",
      "[('“', 'NN'), ('What', 'WP'), ('has', 'VBZ'), ('been', 'VBN'), ('decided', 'VBN'), ('?', '.')]\n",
      "[('They', 'PRP'), ('have', 'VBP'), ('decided', 'VBN'), ('that', 'IN'), ('Buonaparte', 'NNP'), ('has', 'VBZ'), ('burnt', 'VBN'), ('his', 'PRP$'), ('boats', 'NNS'), (',', ','), ('and', 'CC'), ('I', 'PRP'), ('believe', 'VBP'), ('that', 'IN'), ('we', 'PRP'), ('are', 'VBP'), ('ready', 'JJ'), ('to', 'TO'), ('burn', 'VB'), ('ours.', 'RP'), ('”', 'JJ'), ('Prince', 'NNP'), ('Vasíli', 'NNP'), ('always', 'RB'), ('spoke', 'VBD'), ('languidly', 'RB'), (',', ','), ('like', 'IN'), ('an', 'DT'), ('actor', 'NN'), ('repeating', 'VBG'), ('a', 'DT'), ('stale', 'JJ'), ('part', 'NN'), ('.', '.')]\n",
      "[('Anna', 'NNP'), ('Pávlovna', 'NNP'), ('Schérer', 'NNP'), ('on', 'IN'), ('the', 'DT'), ('contrary', 'JJ'), (',', ','), ('despite', 'IN'), ('her', 'PRP$'), ('forty', 'NN'), ('years', 'NNS'), (',', ','), ('overflowed', 'VBD'), ('with', 'IN'), ('animation', 'NN'), ('and', 'CC'), ('impulsiveness', 'NN'), ('.', '.')]\n",
      "[('To', 'TO'), ('be', 'VB'), ('an', 'DT'), ('enthusiast', 'NN'), ('had', 'VBD'), ('become', 'VBN'), ('her', 'PRP$'), ('social', 'JJ'), ('vocation', 'NN'), ('and', 'CC'), (',', ','), ('sometimes', 'RB'), ('even', 'RB'), ('when', 'WRB'), ('she', 'PRP'), ('did', 'VBD'), ('not', 'RB'), ('feel', 'VB'), ('like', 'IN'), ('it', 'PRP'), (',', ','), ('she', 'PRP'), ('became', 'VBD'), ('enthusiastic', 'JJ'), ('in', 'IN'), ('order', 'NN'), ('not', 'RB'), ('to', 'TO'), ('disappoint', 'VB'), ('the', 'DT'), ('expectations', 'NNS'), ('of', 'IN'), ('those', 'DT'), ('who', 'WP'), ('knew', 'VBD'), ('her', 'PRP'), ('.', '.')]\n",
      "[('The', 'DT'), ('subdued', 'VBN'), ('smile', 'NN'), ('which', 'WDT'), (',', ','), ('though', 'IN'), ('it', 'PRP'), ('did', 'VBD'), ('not', 'RB'), ('suit', 'VB'), ('her', 'PRP'), ('faded', 'JJ'), ('features', 'NNS'), (',', ','), ('always', 'RB'), ('played', 'VBN'), ('round', 'RP'), ('her', 'PRP$'), ('lips', 'NNS'), ('expressed', 'VBN'), (',', ','), ('as', 'IN'), ('in', 'IN'), ('a', 'DT'), ('spoiled', 'JJ'), ('child', 'NN'), (',', ','), ('a', 'DT'), ('continual', 'JJ'), ('consciousness', 'NN'), ('of', 'IN'), ('her', 'PRP$'), ('charming', 'NN'), ('defect', 'NN'), (',', ','), ('which', 'WDT'), ('she', 'PRP'), ('neither', 'DT'), ('wished', 'VBD'), (',', ','), ('nor', 'CC'), ('could', 'MD'), (',', ','), ('nor', 'CC'), ('considered', 'VBD'), ('it', 'PRP'), ('necessary', 'JJ'), (',', ','), ('to', 'TO'), ('correct', 'VB'), ('.', '.')]\n",
      "[('In', 'IN'), ('the', 'DT'), ('midst', 'NN'), ('of', 'IN'), ('a', 'DT'), ('conversation', 'NN'), ('on', 'IN'), ('political', 'JJ'), ('matters', 'NNS'), ('Anna', 'NNP'), ('Pávlovna', 'NNP'), ('burst', 'VBZ'), ('out', 'RP'), (':', ':'), ('“', 'NN'), ('Oh', 'NNP'), (',', ','), ('don', 'NN'), ('’', 'NNP'), ('t', 'NN'), ('speak', 'NN'), ('to', 'TO'), ('me', 'PRP'), ('of', 'IN'), ('Austria', 'NNP'), ('.', '.')]\n",
      "[('Perhaps', 'RB'), ('I', 'PRP'), ('don', 'VBP'), ('’', 'JJ'), ('t', 'NN'), ('understand', 'JJ'), ('things', 'NNS'), (',', ','), ('but', 'CC'), ('Austria', 'NNP'), ('never', 'RB'), ('has', 'VBZ'), ('wished', 'VBN'), (',', ','), ('and', 'CC'), ('does', 'VBZ'), ('not', 'RB'), ('wish', 'VB'), (',', ','), ('for', 'IN'), ('war', 'NN'), ('.', '.')]\n",
      "[('She', 'PRP'), ('is', 'VBZ'), ('betraying', 'VBG'), ('us', 'PRP'), ('!', '.')]\n",
      "[('Russia', 'NNP'), ('alone', 'RB'), ('must', 'MD'), ('save', 'VB'), ('Europe', 'NNP'), ('.', '.')]\n",
      "[('Our', 'PRP$'), ('gracious', 'JJ'), ('sovereign', 'NN'), ('recognizes', 'VBZ'), ('his', 'PRP$'), ('high', 'JJ'), ('vocation', 'NN'), ('and', 'CC'), ('will', 'MD'), ('be', 'VB'), ('true', 'JJ'), ('to', 'TO'), ('it', 'PRP'), ('.', '.')]\n",
      "[('That', 'DT'), ('is', 'VBZ'), ('the', 'DT'), ('one', 'CD'), ('thing', 'NN'), ('I', 'PRP'), ('have', 'VBP'), ('faith', 'VBN'), ('in', 'IN'), ('!', '.')]\n",
      "[('Our', 'PRP$'), ('good', 'JJ'), ('and', 'CC'), ('wonderful', 'JJ'), ('sovereign', 'NN'), ('has', 'VBZ'), ('to', 'TO'), ('perform', 'VB'), ('the', 'DT'), ('noblest', 'JJS'), ('role', 'NN'), ('on', 'IN'), ('earth', 'NN'), (',', ','), ('and', 'CC'), ('he', 'PRP'), ('is', 'VBZ'), ('so', 'RB'), ('virtuous', 'JJ'), ('and', 'CC'), ('noble', 'JJ'), ('that', 'IN'), ('God', 'NNP'), ('will', 'MD'), ('not', 'RB'), ('forsake', 'VB'), ('him', 'PRP'), ('.', '.')]\n",
      "[('He', 'PRP'), ('will', 'MD'), ('fulfill', 'VB'), ('his', 'PRP$'), ('vocation', 'NN'), ('and', 'CC'), ('crush', 'VB'), ('the', 'DT'), ('hydra', 'NN'), ('of', 'IN'), ('revolution', 'NN'), (',', ','), ('which', 'WDT'), ('has', 'VBZ'), ('become', 'VBN'), ('more', 'RBR'), ('terrible', 'JJ'), ('than', 'IN'), ('ever', 'RB'), ('in', 'IN'), ('the', 'DT'), ('person', 'NN'), ('of', 'IN'), ('this', 'DT'), ('murderer', 'NN'), ('and', 'CC'), ('villain', 'NN'), ('!', '.')]\n",
      "[('We', 'PRP'), ('alone', 'RB'), ('must', 'MD'), ('avenge', 'VB'), ('the', 'DT'), ('blood', 'NN'), ('of', 'IN'), ('the', 'DT'), ('just', 'RB'), ('one', 'CD'), ('...', ':'), ('.', '.')]\n",
      "[('Whom', 'NNP'), (',', ','), ('I', 'PRP'), ('ask', 'VBP'), ('you', 'PRP'), (',', ','), ('can', 'MD'), ('we', 'PRP'), ('rely', 'VB'), ('on', 'IN'), ('?', '.'), ('...', ':')]\n",
      "[('England', 'NNP'), ('with', 'IN'), ('her', 'PRP$'), ('commercial', 'JJ'), ('spirit', 'NN'), ('will', 'MD'), ('not', 'RB'), ('and', 'CC'), ('can', 'MD'), ('not', 'RB'), ('understand', 'VB'), ('the', 'DT'), ('Emperor', 'NNP'), ('Alexander', 'NNP'), ('’', 'NNP'), ('s', 'VBD'), ('loftiness', 'NN'), ('of', 'IN'), ('soul', 'NN'), ('.', '.')]\n",
      "[('She', 'PRP'), ('has', 'VBZ'), ('refused', 'VBN'), ('to', 'TO'), ('evacuate', 'VB'), ('Malta', 'NNP'), ('.', '.')]\n",
      "[('She', 'PRP'), ('wanted', 'VBD'), ('to', 'TO'), ('find', 'VB'), (',', ','), ('and', 'CC'), ('still', 'RB'), ('seeks', 'VBZ'), (',', ','), ('some', 'DT'), ('secret', 'JJ'), ('motive', 'NN'), ('in', 'IN'), ('our', 'PRP$'), ('actions', 'NNS'), ('.', '.')]\n",
      "[('What', 'WP'), ('answer', 'NN'), ('did', 'VBD'), ('Novosíltsev', 'NNP'), ('get', 'VB'), ('?', '.')]\n",
      "[('None', 'NN'), ('.', '.')]\n",
      "[('The', 'DT'), ('English', 'NNP'), ('have', 'VBP'), ('not', 'RB'), ('understood', 'VBN'), ('and', 'CC'), ('can', 'MD'), ('not', 'RB'), ('understand', 'VB'), ('the', 'DT'), ('self-abnegation', 'NN'), ('of', 'IN'), ('our', 'PRP$'), ('Emperor', 'NN'), ('who', 'WP'), ('wants', 'VBZ'), ('nothing', 'NN'), ('for', 'IN'), ('himself', 'PRP'), (',', ','), ('but', 'CC'), ('only', 'RB'), ('desires', 'VBZ'), ('the', 'DT'), ('good', 'NN'), ('of', 'IN'), ('mankind', 'NN'), ('.', '.')]\n",
      "[('And', 'CC'), ('what', 'WP'), ('have', 'VBP'), ('they', 'PRP'), ('promised', 'VBN'), ('?', '.')]\n",
      "[('Nothing', 'NN'), ('!', '.')]\n",
      "[('And', 'CC'), ('what', 'WP'), ('little', 'JJ'), ('they', 'PRP'), ('have', 'VBP'), ('promised', 'VBN'), ('they', 'PRP'), ('will', 'MD'), ('not', 'RB'), ('perform', 'VB'), ('!', '.')]\n",
      "[('Prussia', 'NNP'), ('has', 'VBZ'), ('always', 'RB'), ('declared', 'VBN'), ('that', 'IN'), ('Buonaparte', 'NNP'), ('is', 'VBZ'), ('invincible', 'JJ'), (',', ','), ('and', 'CC'), ('that', 'IN'), ('all', 'DT'), ('Europe', 'NNP'), ('is', 'VBZ'), ('powerless', 'JJ'), ('before', 'IN'), ('him', 'PRP'), ('...', ':'), ('.', '.'), ('And', 'CC'), ('I', 'PRP'), ('don', 'VBP'), ('’', 'JJ'), ('t', 'NN'), ('believe', 'VBP'), ('a', 'DT'), ('word', 'NN'), ('that', 'IN'), ('Hardenburg', 'NNP'), ('says', 'VBZ'), (',', ','), ('or', 'CC'), ('Haugwitz', 'NNP'), ('either', 'DT'), ('.', '.')]\n",
      "[('This', 'DT'), ('famous', 'JJ'), ('Prussian', 'JJ'), ('neutrality', 'NN'), ('is', 'VBZ'), ('just', 'RB'), ('a', 'DT'), ('trap', 'NN'), ('.', '.')]\n",
      "[('I', 'PRP'), ('have', 'VBP'), ('faith', 'VBN'), ('only', 'RB'), ('in', 'IN'), ('God', 'NNP'), ('and', 'CC'), ('the', 'DT'), ('lofty', 'JJ'), ('destiny', 'NN'), ('of', 'IN'), ('our', 'PRP$'), ('adored', 'JJ'), ('monarch', 'NN'), ('.', '.')]\n",
      "[('He', 'PRP'), ('will', 'MD'), ('save', 'VB'), ('Europe', 'NNP'), ('!', '.'), ('”', 'NN'), ('She', 'PRP'), ('suddenly', 'RB'), ('paused', 'VBD'), (',', ','), ('smiling', 'VBG'), ('at', 'IN'), ('her', 'PRP$'), ('own', 'JJ'), ('impetuosity', 'NN'), ('.', '.')]\n",
      "[('“', 'NN'), ('I', 'PRP'), ('think', 'VBP'), (',', ','), ('”', 'NNP'), ('said', 'VBD'), ('the', 'DT'), ('prince', 'NN'), ('with', 'IN'), ('a', 'DT'), ('smile', 'NN'), (',', ','), ('“', 'VBP'), ('that', 'IN'), ('if', 'IN'), ('you', 'PRP'), ('had', 'VBD'), ('been', 'VBN'), ('sent', 'VBN'), ('instead', 'RB'), ('of', 'IN'), ('our', 'PRP$'), ('dear', 'JJ'), ('Wintzingerode', 'NNP'), ('you', 'PRP'), ('would', 'MD'), ('have', 'VB'), ('captured', 'VBN'), ('the', 'DT'), ('King', 'NNP'), ('of', 'IN'), ('Prussia', 'NNP'), ('’', 'NNP'), ('s', 'VBD'), ('consent', 'NN'), ('by', 'IN'), ('assault', 'NN'), ('.', '.')]\n",
      "[('You', 'PRP'), ('are', 'VBP'), ('so', 'RB'), ('eloquent', 'JJ'), ('.', '.')]\n",
      "[('Will', 'MD'), ('you', 'PRP'), ('give', 'VB'), ('me', 'PRP'), ('a', 'DT'), ('cup', 'NN'), ('of', 'IN'), ('tea', 'NN'), ('?', '.'), ('”', 'JJ'), ('“', 'NN'), ('In', 'IN'), ('a', 'DT'), ('moment', 'NN'), ('.', '.')]\n",
      "[('À', 'NN'), ('propos', 'NN'), (',', ','), ('”', 'NNP'), ('she', 'PRP'), ('added', 'VBD'), (',', ','), ('becoming', 'VBG'), ('calm', 'NN'), ('again', 'RB'), (',', ','), ('“', 'PRP'), ('I', 'PRP'), ('am', 'VBP'), ('expecting', 'VBG'), ('two', 'CD'), ('very', 'RB'), ('interesting', 'JJ'), ('men', 'NNS'), ('tonight', 'VBD'), (',', ','), ('le', 'JJ'), ('Vicomte', 'NNP'), ('de', 'FW'), ('Mortemart', 'NNP'), (',', ','), ('who', 'WP'), ('is', 'VBZ'), ('connected', 'VBN'), ('with', 'IN'), ('the', 'DT'), ('Montmorencys', 'NNP'), ('through', 'IN'), ('the', 'DT'), ('Rohans', 'NNPS'), (',', ','), ('one', 'CD'), ('of', 'IN'), ('the', 'DT'), ('best', 'JJS'), ('French', 'JJ'), ('families', 'NNS'), ('.', '.')]\n",
      "[('He', 'PRP'), ('is', 'VBZ'), ('one', 'CD'), ('of', 'IN'), ('the', 'DT'), ('genuine', 'JJ'), ('émigrés', 'NN'), (',', ','), ('the', 'DT'), ('good', 'JJ'), ('ones', 'NNS'), ('.', '.')]\n",
      "[('And', 'CC'), ('also', 'RB'), ('the', 'DT'), ('Abbé', 'NNP'), ('Morio', 'NNP'), ('.', '.')]\n",
      "[('Do', 'VB'), ('you', 'PRP'), ('know', 'VB'), ('that', 'DT'), ('profound', 'NN'), ('thinker', 'NN'), ('?', '.')]\n",
      "[('He', 'PRP'), ('has', 'VBZ'), ('been', 'VBN'), ('received', 'VBN'), ('by', 'IN'), ('the', 'DT'), ('Emperor', 'NNP'), ('.', '.')]\n",
      "[('Had', 'NNP'), ('you', 'PRP'), ('heard', 'VBN'), ('?', '.'), ('”', 'JJ'), ('“', 'NN'), ('I', 'PRP'), ('shall', 'MD'), ('be', 'VB'), ('delighted', 'VBN'), ('to', 'TO'), ('meet', 'VB'), ('them', 'PRP'), (',', ','), ('”', 'NNP'), ('said', 'VBD'), ('the', 'DT'), ('prince', 'NN'), ('.', '.')]\n",
      "[('“', 'NNS'), ('But', 'CC'), ('tell', 'VB'), ('me', 'PRP'), (',', ','), ('”', 'VBZ'), ('he', 'PRP'), ('added', 'VBD'), ('with', 'IN'), ('studied', 'JJ'), ('carelessness', 'NN'), ('as', 'IN'), ('if', 'IN'), ('it', 'PRP'), ('had', 'VBD'), ('only', 'RB'), ('just', 'RB'), ('occurred', 'VBN'), ('to', 'TO'), ('him', 'PRP'), (',', ','), ('though', 'IN'), ('the', 'DT'), ('question', 'NN'), ('he', 'PRP'), ('was', 'VBD'), ('about', 'RB'), ('to', 'TO'), ('ask', 'VB'), ('was', 'VBD'), ('the', 'DT'), ('chief', 'JJ'), ('motive', 'NN'), ('of', 'IN'), ('his', 'PRP$'), ('visit', 'NN'), (',', ','), ('“', 'NN'), ('is', 'VBZ'), ('it', 'PRP'), ('true', 'JJ'), ('that', 'IN'), ('the', 'DT'), ('Dowager', 'NNP'), ('Empress', 'NNP'), ('wants', 'VBZ'), ('Baron', 'NNP'), ('Funke', 'NNP'), ('to', 'TO'), ('be', 'VB'), ('appointed', 'VBN'), ('first', 'RB'), ('secretary', 'NN'), ('at', 'IN'), ('Vienna', 'NNP'), ('?', '.')]\n",
      "[('The', 'DT'), ('baron', 'NN'), ('by', 'IN'), ('all', 'DT'), ('accounts', 'NNS'), ('is', 'VBZ'), ('a', 'DT'), ('poor', 'JJ'), ('creature.', 'NN'), ('”', 'NNP'), ('Prince', 'NNP'), ('Vasíli', 'NNP'), ('wished', 'VBD'), ('to', 'TO'), ('obtain', 'VB'), ('this', 'DT'), ('post', 'NN'), ('for', 'IN'), ('his', 'PRP$'), ('son', 'NN'), (',', ','), ('but', 'CC'), ('others', 'NNS'), ('were', 'VBD'), ('trying', 'VBG'), ('through', 'IN'), ('the', 'DT'), ('Dowager', 'NNP'), ('Empress', 'NNP'), ('Márya', 'NNP'), ('Fëdorovna', 'NNP'), ('to', 'TO'), ('secure', 'VB'), ('it', 'PRP'), ('for', 'IN'), ('the', 'DT'), ('baron', 'NN'), ('.', '.')]\n",
      "[('Anna', 'NNP'), ('Pávlovna', 'NNP'), ('almost', 'RB'), ('closed', 'VBD'), ('her', 'PRP'), ('eyes', 'NNS'), ('to', 'TO'), ('indicate', 'VB'), ('that', 'IN'), ('neither', 'DT'), ('she', 'PRP'), ('nor', 'CC'), ('anyone', 'NN'), ('else', 'RB'), ('had', 'VBD'), ('a', 'DT'), ('right', 'NN'), ('to', 'TO'), ('criticize', 'VB'), ('what', 'WP'), ('the', 'DT'), ('Empress', 'NN'), ('desired', 'VBD'), ('or', 'CC'), ('was', 'VBD'), ('pleased', 'VBN'), ('with', 'IN'), ('.', '.')]\n",
      "[('“', 'JJ'), ('Baron', 'NNP'), ('Funke', 'NNP'), ('has', 'VBZ'), ('been', 'VBN'), ('recommended', 'VBN'), ('to', 'TO'), ('the', 'DT'), ('Dowager', 'NNP'), ('Empress', 'NNP'), ('by', 'IN'), ('her', 'PRP$'), ('sister', 'NN'), (',', ','), ('”', 'NNP'), ('was', 'VBD'), ('all', 'DT'), ('she', 'PRP'), ('said', 'VBD'), (',', ','), ('in', 'IN'), ('a', 'DT'), ('dry', 'JJ'), ('and', 'CC'), ('mournful', 'JJ'), ('tone', 'NN'), ('.', '.')]\n",
      "[('As', 'IN'), ('she', 'PRP'), ('named', 'VBD'), ('the', 'DT'), ('Empress', 'NNP'), (',', ','), ('Anna', 'NNP'), ('Pávlovna', 'NNP'), ('’', 'NNP'), ('s', 'VBD'), ('face', 'NN'), ('suddenly', 'RB'), ('assumed', 'VBD'), ('an', 'DT'), ('expression', 'NN'), ('of', 'IN'), ('profound', 'NN'), ('and', 'CC'), ('sincere', 'JJ'), ('devotion', 'NN'), ('and', 'CC'), ('respect', 'NN'), ('mingled', 'VBN'), ('with', 'IN'), ('sadness', 'NN'), (',', ','), ('and', 'CC'), ('this', 'DT'), ('occurred', 'VBD'), ('every', 'DT'), ('time', 'NN'), ('she', 'PRP'), ('mentioned', 'VBD'), ('her', 'PRP'), ('illustrious', 'JJ'), ('patroness', 'NN'), ('.', '.')]\n",
      "[('She', 'PRP'), ('added', 'VBD'), ('that', 'IN'), ('Her', 'NNP'), ('Majesty', 'NNP'), ('had', 'VBD'), ('deigned', 'VBN'), ('to', 'TO'), ('show', 'VB'), ('Baron', 'NNP'), ('Funke', 'NNP'), ('beaucoup', 'NN'), ('d', 'NN'), ('’', 'NNP'), ('estime', 'NN'), (',', ','), ('and', 'CC'), ('again', 'RB'), ('her', 'PRP$'), ('face', 'NN'), ('clouded', 'VBD'), ('over', 'IN'), ('with', 'IN'), ('sadness', 'NN'), ('.', '.')]\n",
      "[('The', 'DT'), ('prince', 'NN'), ('was', 'VBD'), ('silent', 'JJ'), ('and', 'CC'), ('looked', 'VBD'), ('indifferent', 'NN'), ('.', '.')]\n",
      "[('But', 'CC'), (',', ','), ('with', 'IN'), ('the', 'DT'), ('womanly', 'NN'), ('and', 'CC'), ('courtierlike', 'NN'), ('quickness', 'NN'), ('and', 'CC'), ('tact', 'JJ'), ('habitual', 'JJ'), ('to', 'TO'), ('her', 'PRP$'), (',', ','), ('Anna', 'NNP'), ('Pávlovna', 'NNP'), ('wished', 'VBD'), ('both', 'DT'), ('to', 'TO'), ('rebuke', 'VB'), ('him', 'PRP'), ('(', '('), ('for', 'IN'), ('daring', 'VBG'), ('to', 'TO'), ('speak', 'VB'), ('as', 'IN'), ('he', 'PRP'), ('had', 'VBD'), ('done', 'VBN'), ('of', 'IN'), ('a', 'DT'), ('man', 'NN'), ('recommended', 'VBN'), ('to', 'TO'), ('the', 'DT'), ('Empress', 'NNP'), (')', ')'), ('and', 'CC'), ('at', 'IN'), ('the', 'DT'), ('same', 'JJ'), ('time', 'NN'), ('to', 'TO'), ('console', 'VB'), ('him', 'PRP'), (',', ','), ('so', 'IN'), ('she', 'PRP'), ('said', 'VBD'), (':', ':'), ('“', 'NN'), ('Now', 'RB'), ('about', 'IN'), ('your', 'PRP$'), ('family', 'NN'), ('.', '.')]\n",
      "[('Do', 'VB'), ('you', 'PRP'), ('know', 'VB'), ('that', 'IN'), ('since', 'IN'), ('your', 'PRP$'), ('daughter', 'NN'), ('came', 'VBD'), ('out', 'RP'), ('everyone', 'NN'), ('has', 'VBZ'), ('been', 'VBN'), ('enraptured', 'VBN'), ('by', 'IN'), ('her', 'PRP'), ('?', '.')]\n",
      "[('They', 'PRP'), ('say', 'VBP'), ('she', 'PRP'), ('is', 'VBZ'), ('amazingly', 'RB'), ('beautiful.', 'JJ'), ('”', 'VBP'), ('The', 'DT'), ('prince', 'NN'), ('bowed', 'VBD'), ('to', 'TO'), ('signify', 'VB'), ('his', 'PRP$'), ('respect', 'NN'), ('and', 'CC'), ('gratitude', 'NN'), ('.', '.')]\n",
      "[('“', 'NN'), ('I', 'PRP'), ('often', 'RB'), ('think', 'VBP'), (',', ','), ('”', 'VBZ'), ('she', 'PRP'), ('continued', 'VBD'), ('after', 'IN'), ('a', 'DT'), ('short', 'JJ'), ('pause', 'NN'), (',', ','), ('drawing', 'VBG'), ('nearer', 'NN'), ('to', 'TO'), ('the', 'DT'), ('prince', 'NN'), ('and', 'CC'), ('smiling', 'VBG'), ('amiably', 'RB'), ('at', 'IN'), ('him', 'PRP'), ('as', 'IN'), ('if', 'IN'), ('to', 'TO'), ('show', 'VB'), ('that', 'DT'), ('political', 'JJ'), ('and', 'CC'), ('social', 'JJ'), ('topics', 'NNS'), ('were', 'VBD'), ('ended', 'VBN'), ('and', 'CC'), ('the', 'DT'), ('time', 'NN'), ('had', 'VBD'), ('come', 'VBN'), ('fo', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "# len(new_words)\n",
    "sent=sent_tokenize(doc)\n",
    "\n",
    "words=[]\n",
    "for i in range(len(sent)):\n",
    "    words.append(word_tokenize(sent[i]))\n",
    "\n",
    "for word in words:\n",
    "    print(nltk.pos_tag(word))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using SpaCy Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/usr/anaconda3/lib/python3.6/site-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.23) or chardet (2.3.0) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "from spacy.tokenizer import Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization using Spacy Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_words=[]\n",
    "spacy_doc=nlp(doc)\n",
    "for token in spacy_doc:\n",
    "    spacy_words.append(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[sh,\n",
       " to,\n",
       " be,\n",
       " believed,\n",
       " .,\n",
       "  ,\n",
       " “,\n",
       " Do,\n",
       " n’t,\n",
       " tease,\n",
       " !,\n",
       " Well,\n",
       " ,,\n",
       " and,\n",
       " what,\n",
       " has,\n",
       " been,\n",
       " decided,\n",
       " about,\n",
       " Novosíltsev]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy_words[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatizing using Spacy Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_lemma_words=[]\n",
    "for token in spacy_doc:\n",
    "    spacy_lemma_words.append(token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sh',\n",
       " 'to',\n",
       " 'be',\n",
       " 'believe',\n",
       " '.',\n",
       " ' ',\n",
       " '\"',\n",
       " 'do',\n",
       " 'not',\n",
       " 'tease',\n",
       " '!',\n",
       " 'well',\n",
       " ',',\n",
       " 'and',\n",
       " 'what',\n",
       " 'have',\n",
       " 'be',\n",
       " 'decide',\n",
       " 'about',\n",
       " 'novosíltsev']"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy_lemma_words[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS_Tagging using SPACY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_pos=[]\n",
    "spacy_doc=nlp(doc)\n",
    "for token in spacy_doc:\n",
    "    spacy_pos.append([token,token.pos_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[sh, 'PRON'],\n",
       " [to, 'PART'],\n",
       " [be, 'VERB'],\n",
       " [believed, 'VERB'],\n",
       " [., 'PUNCT'],\n",
       " [ , 'SPACE'],\n",
       " [“, 'PUNCT'],\n",
       " [Do, 'VERB'],\n",
       " [n’t, 'ADV'],\n",
       " [tease, 'VERB'],\n",
       " [!, 'PUNCT'],\n",
       " [Well, 'INTJ'],\n",
       " [,, 'PUNCT'],\n",
       " [and, 'CCONJ'],\n",
       " [what, 'NOUN'],\n",
       " [has, 'VERB'],\n",
       " [been, 'VERB'],\n",
       " [decided, 'VERB'],\n",
       " [about, 'ADP'],\n",
       " [Novosíltsev, 'PROPN']]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy_pos[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc=[]\n",
    "with open('War_And_Peace.txt', 'r',encoding='utf-8') as myfile:\n",
    "    doc= myfile.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_doc=doc[3000:3050]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import itertools as it\n",
    "\n",
    "nlp=spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CHAPTER XIII\\n \\n When Natásha ran out of the drawing room she only went as far as the\\n conservatory. There she paused and stood listening to the conversation\\n in the drawing room, waiting for Borís to come out. She was already\\n growing impatient, and stamped her foot, ready to cry at his not coming\\n at once, when she heard the young man’s discreet steps approaching\\n neither quickly nor slowly. At this Natásha dashed swiftly among the\\n flower tubs and hid there.\\n \\n Borís paused in the middle of the room, looked round, brushed a little\\n dust from the sleeve of his uniform, and going up to a mirror examined\\n his handsome face. Natásha, very still, peered out from her ambush,\\n waiting to see what he would do. He stood a little while before the\\n glass, smiled, and walked toward the other door. Natásha was about to\\n call him but changed her mind. “Let him look for me,” thought she.\\n Hardly had Borís gone than Sónya, flushed, in tears, and muttering\\n angrily, came in at the other door. Natásha checked her first impulse\\n to run out to her, and remained in her hiding place, watching—as\\n under an invisible cap—to see what went on in the world. She was\\n experiencing a new and peculiar pleasure. Sónya, muttering to herself,\\n kept looking round toward the drawing room door. It opened and Nicholas\\n came in.\\n \\n “Sónya, what is the matter with you? How can you?” said he, running\\n up to her.\\n \\n “It’s nothing, nothing; leave me alone!” sobbed Sónya.\\n \\n “Ah, I know what it is.”\\n \\n “Well, if you do, so much the better, and you can go back to her!”\\n \\n “Só-o-onya! Look here! How can you torture me and yourself like that,\\n for a mere fancy?” said Nicholas taking her hand.\\n \\n Sónya did not pull it away, and left off crying. Natásha, not stirring\\n and scarcely breathing, watched from her ambush with sparkling eyes.\\n “What will happen now?” thought she.\\n \\n “Sónya! What is anyone in the world to me? You alone are\\n everything!” said Nicholas. “And I will prove it to you.”\\n \\n “I don’t like you to talk like that.”\\n \\n “Well, then, I won’t; only forgive me, Sónya!” He drew her to him\\n and kissed her.\\n \\n “Oh, how nice,” thought Natásha; and when Sónya and Nicholas had\\n gone out of the conservatory she followed and called Borís to her.\\n'"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_string=' '.join(test_doc)\n",
    "test_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHAPTER XIII\n",
      " \n",
      " When Natásha ran out of the drawing room she only went as far as the\n",
      " conservatory. There she paused and stood listening to the conversation\n",
      " in the drawing room, waiting for Borís to come out. She was already\n",
      " growing impatient, and stamped her foot, ready to cry at his not coming\n",
      " at once, when she heard the young man’s discreet steps approaching\n",
      " neither quickly nor slowly. At this Natásha dashed swiftly among the\n",
      " flower tubs and hid there.\n",
      " \n",
      " Borís paused in the middle of the room, looked round, brushed a little\n",
      " dust from the sleeve of his uniform, and going up to a mirror examined\n",
      " his handsome face. Natásha, very still, peered out from her ambush,\n",
      " waiting to see what he would do. He stood a little while before the\n",
      " glass, smiled, and walked toward the other door. Natásha was about to\n",
      " call him but changed her mind. “Let him look for me,” thought she.\n",
      " Hardly had Borís gone than Sónya, flushed, in tears, and muttering\n",
      " angrily, came in at the other door. Natásha checked her first impulse\n",
      " to run out to her, and remained in her hiding place, watching—as\n",
      " under an invisible cap—to see what went on in the world. She was\n",
      " experiencing a new and peculiar pleasure. Sónya, muttering to herself,\n",
      " kept looking round toward the drawing room door. It opened and Nicholas\n",
      " came in.\n",
      " \n",
      " “Sónya, what is the matter with you? How can you?” said he, running\n",
      " up to her.\n",
      " \n",
      " “It’s nothing, nothing; leave me alone!” sobbed Sónya.\n",
      " \n",
      " “Ah, I know what it is.”\n",
      " \n",
      " “Well, if you do, so much the better, and you can go back to her!”\n",
      " \n",
      " “Só-o-onya! Look here! How can you torture me and yourself like that,\n",
      " for a mere fancy?” said Nicholas taking her hand.\n",
      " \n",
      " Sónya did not pull it away, and left off crying. Natásha, not stirring\n",
      " and scarcely breathing, watched from her ambush with sparkling eyes.\n",
      " “What will happen now?” thought she.\n",
      " \n",
      " “Sónya! What is anyone in the world to me? You alone are\n",
      " everything!” said Nicholas. “And I will prove it to you.”\n",
      " \n",
      " “I don’t like you to talk like that.”\n",
      " \n",
      " “Well, then, I won’t; only forgive me, Sónya!” He drew her to him\n",
      " and kissed her.\n",
      " \n",
      " “Oh, how nice,” thought Natásha; and when Sónya and Nicholas had\n",
      " gone out of the conservatory she followed and called Borís to her.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parsed_string=nlp(test_string)\n",
    "print(parsed_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1:\n",
      "CHAPTER XIII\n",
      " \n",
      "  \n",
      "\n",
      "Sentence 2:\n",
      "When Natásha ran out of the drawing room she only went as far as the\n",
      " conservatory. \n",
      "\n",
      "Sentence 3:\n",
      "There she paused and stood listening to the conversation\n",
      " in the drawing room, waiting for Borís to come out. \n",
      "\n",
      "Sentence 4:\n",
      "She was already\n",
      " growing impatient, and stamped her foot, ready to cry at his not coming\n",
      " at once, when she heard the young man’s discreet steps approaching\n",
      " neither quickly nor slowly. \n",
      "\n",
      "Sentence 5:\n",
      "At this Natásha dashed swiftly among the\n",
      " flower tubs and hid there.\n",
      " \n",
      "  \n",
      "\n",
      "Sentence 6:\n",
      "Borís paused in the middle of the room, looked round, brushed a little\n",
      " dust from the sleeve of his uniform, and going up to a mirror examined\n",
      " his handsome face. \n",
      "\n",
      "Sentence 7:\n",
      "Natásha, very still, peered out from her ambush,\n",
      " waiting to see what he would do. \n",
      "\n",
      "Sentence 8:\n",
      "He stood a little while before the\n",
      " glass, smiled, and walked toward the other door. \n",
      "\n",
      "Sentence 9:\n",
      "Natásha was about to\n",
      " call him but changed her mind. \n",
      "\n",
      "Sentence 10:\n",
      "“ \n",
      "\n",
      "Sentence 11:\n",
      "Let him look for me,” thought she.\n",
      "  \n",
      "\n",
      "Sentence 12:\n",
      "Hardly had Borís gone than Sónya, flushed, in tears, and muttering\n",
      " angrily, came in at the other door. \n",
      "\n",
      "Sentence 13:\n",
      "Natásha checked her first impulse\n",
      " to run out to her, and remained in her hiding place, watching—as\n",
      " under an invisible cap—to see what went on in the world. \n",
      "\n",
      "Sentence 14:\n",
      "She was\n",
      " experiencing a new and peculiar pleasure. \n",
      "\n",
      "Sentence 15:\n",
      "Sónya, muttering to herself,\n",
      " kept looking round toward the drawing room door. \n",
      "\n",
      "Sentence 16:\n",
      "It opened and Nicholas\n",
      " came in.\n",
      " \n",
      "  \n",
      "\n",
      "Sentence 17:\n",
      "“Sónya, what is the matter with you? \n",
      "\n",
      "Sentence 18:\n",
      "How can you? \n",
      "\n",
      "Sentence 19:\n",
      "” said he, running\n",
      " up to her.\n",
      " \n",
      "  \n",
      "\n",
      "Sentence 20:\n",
      "“ \n",
      "\n",
      "Sentence 21:\n",
      "It’s nothing, nothing; leave me alone! \n",
      "\n",
      "Sentence 22:\n",
      "” \n",
      "\n",
      "Sentence 23:\n",
      "sobbed Sónya.\n",
      " \n",
      "  \n",
      "\n",
      "Sentence 24:\n",
      "“ \n",
      "\n",
      "Sentence 25:\n",
      "Ah, I know what it is. \n",
      "\n",
      "Sentence 26:\n",
      "”\n",
      " \n",
      "  \n",
      "\n",
      "Sentence 27:\n",
      "“ \n",
      "\n",
      "Sentence 28:\n",
      "Well, if you do, so much the better, and you can go back to her! \n",
      "\n",
      "Sentence 29:\n",
      "”\n",
      " \n",
      "  \n",
      "\n",
      "Sentence 30:\n",
      "“Só-o-onya! \n",
      "\n",
      "Sentence 31:\n",
      "Look here! \n",
      "\n",
      "Sentence 32:\n",
      "How can you torture me and yourself like that,\n",
      " for a mere fancy? \n",
      "\n",
      "Sentence 33:\n",
      "” said Nicholas taking her hand.\n",
      " \n",
      "  \n",
      "\n",
      "Sentence 34:\n",
      "Sónya did not pull it away, and left off crying. \n",
      "\n",
      "Sentence 35:\n",
      "Natásha, not stirring\n",
      " and scarcely breathing, watched from her ambush with sparkling eyes.\n",
      "  \n",
      "\n",
      "Sentence 36:\n",
      "“ \n",
      "\n",
      "Sentence 37:\n",
      "What will happen now? \n",
      "\n",
      "Sentence 38:\n",
      "” thought she.\n",
      " \n",
      "  \n",
      "\n",
      "Sentence 39:\n",
      "“Sónya! \n",
      "\n",
      "Sentence 40:\n",
      "What is anyone in the world to me? \n",
      "\n",
      "Sentence 41:\n",
      "You alone are\n",
      " everything! \n",
      "\n",
      "Sentence 42:\n",
      "” said Nicholas. \n",
      "\n",
      "Sentence 43:\n",
      "“ \n",
      "\n",
      "Sentence 44:\n",
      "And I will prove it to you. \n",
      "\n",
      "Sentence 45:\n",
      "”\n",
      " \n",
      "  \n",
      "\n",
      "Sentence 46:\n",
      "“ \n",
      "\n",
      "Sentence 47:\n",
      "I don’t like you to talk like that. \n",
      "\n",
      "Sentence 48:\n",
      "”\n",
      " \n",
      "  \n",
      "\n",
      "Sentence 49:\n",
      "“ \n",
      "\n",
      "Sentence 50:\n",
      "Well, then, I won’t; only forgive me, Sónya! \n",
      "\n",
      "Sentence 51:\n",
      "” \n",
      "\n",
      "Sentence 52:\n",
      "He drew her to him\n",
      " and kissed her.\n",
      " \n",
      "  \n",
      "\n",
      "Sentence 53:\n",
      "“ \n",
      "\n",
      "Sentence 54:\n",
      "Oh, how nice,” thought Natásha; and when Sónya and Nicholas had\n",
      " gone out of the conservatory she followed and called Borís to her.\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Sentence Detection\n",
    "\n",
    "for num,sentence in enumerate(parsed_string.sents):\n",
    "    print(\"Sentence {}:\".format(num+1))\n",
    "    print(sentence,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity 1: Natásha - GPE\n",
      "\n",
      "Entity 2: Borís - PERSON\n",
      "\n",
      "Entity 3: Natásha - GPE\n",
      "\n",
      "Entity 4: Natásha - GPE\n",
      "\n",
      "Entity 5: Natásha - GPE\n",
      "\n",
      "Entity 6: Borís - PERSON\n",
      "\n",
      "Entity 7: Sónya - ORG\n",
      "\n",
      "Entity 8: Natásha - GPE\n",
      "\n",
      "Entity 9: first - ORDINAL\n",
      "\n",
      "Entity 10: Sónya - ORG\n",
      "\n",
      "Entity 11: Nicholas\n",
      "  - PERSON\n",
      "\n",
      "Entity 12: Sónya - ORG\n",
      "\n",
      "Entity 13: Sónya - ORG\n",
      "\n",
      "Entity 14: Nicholas - PERSON\n",
      "\n",
      "Entity 15: Sónya - ORG\n",
      "\n",
      "Entity 16: Natásha - GPE\n",
      "\n",
      "Entity 17: Nicholas - PERSON\n",
      "\n",
      "Entity 18: Sónya - ORG\n",
      "\n",
      "Entity 19: Natásha - GPE\n",
      "\n",
      "Entity 20: Sónya - ORG\n",
      "\n",
      "Entity 21: Nicholas - PERSON\n",
      "\n",
      "Entity 22: Borís - PERSON\n",
      "\n",
      "Entity 23: \n",
      " - GPE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Named Entity Detection\n",
    "\n",
    "for num,entity in enumerate(parsed_string.ents):\n",
    "    print('Entity {}:'.format(num+1),entity,'-',entity.label_)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token_text</th>\n",
       "      <th>Part of speech Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CHAPTER</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XIII</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n \\n</td>\n",
       "      <td>SPACE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>When</td>\n",
       "      <td>ADV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Natásha</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ran</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>out</td>\n",
       "      <td>ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>of</td>\n",
       "      <td>ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>drawing</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  token_text Part of speech Tag\n",
       "0    CHAPTER               NOUN\n",
       "1       XIII               NOUN\n",
       "2     \\n \\n               SPACE\n",
       "3       When                ADV\n",
       "4    Natásha              PROPN\n",
       "5        ran               VERB\n",
       "6        out                ADP\n",
       "7         of                ADP\n",
       "8        the                DET\n",
       "9    drawing               NOUN"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Part of Speech Tagging\n",
    "\n",
    "token_text=[token.orth_ for token in parsed_string]\n",
    "token_pos=[token.pos_ for token in parsed_string]\n",
    "c=list(zip(token_text,token_pos))\n",
    "pd.DataFrame(list(zip(token_text,token_pos)),columns=['token_text','Part of speech Tag']).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>Token Lemma</th>\n",
       "      <th>Token Shape</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CHAPTER</td>\n",
       "      <td>chapter</td>\n",
       "      <td>XXXX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XIII</td>\n",
       "      <td>xiii</td>\n",
       "      <td>XXXX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n \\n</td>\n",
       "      <td>\\n \\n</td>\n",
       "      <td>\\n \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>When</td>\n",
       "      <td>when</td>\n",
       "      <td>Xxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Natásha</td>\n",
       "      <td>natásha</td>\n",
       "      <td>Xxxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ran</td>\n",
       "      <td>run</td>\n",
       "      <td>xxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>out</td>\n",
       "      <td>out</td>\n",
       "      <td>xxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "      <td>xx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>xxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>drawing</td>\n",
       "      <td>drawing</td>\n",
       "      <td>xxxx</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Token Token Lemma Token Shape\n",
       "0  CHAPTER     chapter        XXXX\n",
       "1     XIII        xiii        XXXX\n",
       "2   \\n \\n       \\n \\n       \\n \\n \n",
       "3     When        when        Xxxx\n",
       "4  Natásha     natásha       Xxxxx\n",
       "5      ran         run         xxx\n",
       "6      out         out         xxx\n",
       "7       of          of          xx\n",
       "8      the         the         xxx\n",
       "9  drawing     drawing        xxxx"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_lemma=[token.lemma_ for token in parsed_string]\n",
    "token_shape=[token.shape_ for token in parsed_string]\n",
    "pd.DataFrame(list(zip(token_text,token_lemma,token_shape)),columns=['Token','Token Lemma','Token Shape']).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>Token Entity</th>\n",
       "      <th>Token inside or outside</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CHAPTER</td>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XIII</td>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n \\n</td>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>When</td>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Natásha</td>\n",
       "      <td>GPE</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ran</td>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>out</td>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>of</td>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>the</td>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>drawing</td>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Token Token Entity Token inside or outside\n",
       "0  CHAPTER                                    O\n",
       "1     XIII                                    O\n",
       "2   \\n \\n                                     O\n",
       "3     When                                    O\n",
       "4  Natásha          GPE                       B\n",
       "5      ran                                    O\n",
       "6      out                                    O\n",
       "7       of                                    O\n",
       "8      the                                    O\n",
       "9  drawing                                    O"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_entity_type=[token.ent_type_ for token in parsed_string]\n",
    "token_entity_iob=[token.ent_iob_ for token in parsed_string]\n",
    "pd.DataFrame(list(zip(token_text,token_entity_type,token_entity_iob)),columns=['Token','Token Entity','Token inside or outside']).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>log-probability</th>\n",
       "      <th>stop?</th>\n",
       "      <th>punctuation?</th>\n",
       "      <th>whitespace?</th>\n",
       "      <th>number?</th>\n",
       "      <th>outofvocab?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CHAPTER</td>\n",
       "      <td>-20.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XIII</td>\n",
       "      <td>-20.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n \\n</td>\n",
       "      <td>-20.0</td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>When</td>\n",
       "      <td>-20.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Natásha</td>\n",
       "      <td>-20.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ran</td>\n",
       "      <td>-20.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>out</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>of</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>the</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>drawing</td>\n",
       "      <td>-20.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      text  log-probability stop? punctuation? whitespace? number? outofvocab?\n",
       "0  CHAPTER            -20.0                                                Yes\n",
       "1     XIII            -20.0                                                Yes\n",
       "2   \\n \\n             -20.0                Yes                             Yes\n",
       "3     When            -20.0                                                Yes\n",
       "4  Natásha            -20.0                                                Yes\n",
       "5      ran            -20.0                                                Yes\n",
       "6      out            -20.0   Yes                                          Yes\n",
       "7       of            -20.0   Yes                                          Yes\n",
       "8      the            -20.0   Yes                                          Yes\n",
       "9  drawing            -20.0                                                Yes"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_attributes=[(token.orth_,token.prob,token.is_stop,token.is_space,token.is_punct,token.like_num,token.is_oov) for token in parsed_string]\n",
    "df=pd.DataFrame(token_attributes,columns=['text','log-probability','stop?','punctuation?','whitespace?','number?','outofvocab?'])\n",
    "df.loc[:, 'stop?':'outofvocab?'] = (df.loc[:, 'stop?':'outofvocab?'].applymap(lambda x: u'Yes' if x else u''))\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Phrase Remodelling\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
